---
tags:
  - 计算机
  - 教程
  - AI
  - 重要文献
title: 深度学习笔记
---


## Some mathematics || 数学基础
![[Snipaste_2025-02-19_10-49-25.png|225]]



## Pytorch Basic Instructions || Pytorch 基础使用指南



### Dataset

dataset: 像是一个垃圾分类器，提供一种方式去获取数据及其 label
dataloader：像是一个垃圾压缩机（打包机），为后面的网络提供不同的数据形式
![[Pasted image 20250219210157.png|425]]


``` python
# 引用的库
from torch.utils.data import Dataset
```
注：DataLoader 也在 `torch.utils.data` 之中。

#### 使用方法

一般的使用方法如下：
``` python
class Mydata(Dataset):  
    def __init__(self, root_dir, label_dir):  
        self.root_dir = root_dir  
        self.label_dir = label_dir  
        self.path = os.path.join(self.root_dir, self.label_dir)  
        self.img_path_list = os.listdir(self.path)  
  
  
    def __getitem__(self, index):  
        img_name = self.img_path_list[index]  
        img_item_path = os.path.join(self.root_dir, self.label_dir, img_name)
        img = Image.open(img_item_path)  
        label = self.label_dir  
        return img, label  
  
  
    def __len__(self):  
        return len(self.img_path_list)  
  
if __name__ == "main":  
    root_dir = "dataset/train"  
    ant_dir = "ants"  
    ants_dataset = Mydata(root_dir, ant_dir)  
    img, label = ants_dataset[5]
```



#### **字符画形式解释 `os.path.join()`**

假设：

- `root_dir = "dataset/train"`
    
- `label_dir = "ants"`
    
- `img_name = "image_001.jpg"`
    

则，路径拼接过程：
```
root_dir:      dataset/train
label_dir:     ants
img_name:      image_001.jpg

1. os.path.join(root_dir, label_dir):    dataset/train/ants
2. os.path.join(root_dir, label_dir, img_name):    dataset/train/ants/image_001.jpg
```


``` python
root_dir: dataset/train
          |
          +-- label_dir: ants
                       |
                       +-- img_name: image_001.jpg
```



#### **代码解释** （summoned by Kimi）

这段代码定义了一个名为 `Mydata` 的类，它继承自 PyTorch 的 `Dataset` 类，用于加载和处理图像数据集。以下是代码的逐步解释：

##### **1. `__init__` 方法**

`__init__` 是类的初始化方法，用于设置数据集的基本路径和加载图像文件路径列表。

```python
def __init__(self, root_dir, label_dir):
    self.root_dir = root_dir  # 数据集的根目录
    self.label_dir = label_dir  # 数据集的标签目录（例如 "ants"）
    self.path = os.path.join(self.root_dir, self.label_dir)  # 拼接完整的路径
    self.img_path_list = os.listdir(self.path)  # 获取该路径下所有图像文件的名称
```

- **`os.path.join()`**：用于拼接路径。它会根据操作系统的路径分隔符（Windows 是 `\`，Linux/Unix 是 `/`）正确地拼接路径。
    
- **`os.listdir()`**：列出指定路径下的所有文件和文件夹名称。
    

##### **2. `__getitem__` 方法**

`__getitem__` 是一个特殊方法，用于根据索引获取数据集中的单个样本（图像和标签）。

```python
def __getitem__(self, index):
    img_name = self.img_path_list[index]  # 获取索引对应的图像文件名
    img_item_path = os.path.join(self.root_dir, self.label_dir, img_name)  # 拼接完整的图像路径
    img = Image.open(img_item_path)  # 使用 PIL 打开图像
    label = self.label_dir  # 标签是目录名称（例如 "ants"）
    return img, label  # 返回图像和标签
```

- 这个方法允许我们通过索引访问数据集中的图像和标签，例如 `ants_dataset[5]`。
    

##### **3. 测试代码**


```python
if __name__ == "__main__":
    root_dir = "dataset/train"  # 数据集的根目录
    ant_dir = "ants"  # 标签目录
    ants_dataset = Mydata(root_dir, ant_dir)  # 创建 Mydata 实例
    img, label = ants_dataset[5]  # 获取索引为 5 的图像和标签
```

- 这段代码创建了一个 `Mydata` 实例，并通过索引 `[5]` 获取第 6 张图像及其标签。
    

---


### TensorBoard


`TensorBoard` 和 `SummaryWriter` 是 PyTorch 生态系统中用于可视化和记录训练过程的工具，主要用于帮助开发者更好地理解和监控模型的训练情况。以下是它们的主要功能和用途：

``` python
# 引用的库
from torch.utils.tensorboard import SummaryWriter
```

1. **定义：**
    
    - TensorBoard 是一个可视化工具，最初是为 TensorFlow 设计的，但后来被广泛应用于 PyTorch 等其他深度学习框架。
        
    - 它通过读取日志文件来生成交互式的可视化图表，帮助用户直观地理解训练过程。
        
2. 功能：标量可视化、图像处理可视化

#### 标量可视化

```python
from torch.utils.tensorboard import SummaryWriter  
  
writer = SummaryWriter("logs")   # 参数：存储的文件夹名称, 这里叫logs
# log_dir (string): Save directory location. Default is runs/**CURRENT_DATETIME_HOSTNAME**, which changes after each run.
  

for i in range(100):  
	# 下方操作：添加标量
    writer.add_scalar("y=x^2", i*i, i)  # 参数：标题; x; y
  
  
writer.close()
```

SummaryWriter 的文件存储位置如图。
![[Pasted image 20250220095302.png|350]]


执行上述代码后，终端切到相应的环境（此时此刻我用的环境叫 pytorch），输入指令
```powershell
tensorboard --logdir=logs 
```

如果要制定端口，指令可以加上 `--port=23333` 这种东西

然后出现：

![[Pasted image 20250220095007.png|600]]

点击这个网址出现的就是 tensorboard 的可视化窗口，长这个样子


![[Pasted image 20250220095051.png|500]]


#### 图像处理可视化

函数定义及重要注释内容（有删减）如下：

```python
def add_image(self, tag, img_tensor, global_step=None, walltime=None, dataformats='CHW'):  
    """Add image data to summary.  
  
    Note that this requires the ``pillow`` package.  
    
    	Args: || 参数：
    tag (string): Data identifier
    img_tensor (torch.Tensor, numpy.array, or string/blobname): Image data 
	 || img_tensor传参只能是torch.Tensor, np.array, string中的一个,PIL格式不能传
    global_step (int): Global step value to record || 训练的步数,手动标记
    
    	Shape: || 图像形状：
    默认是C-H-W，也就是通道channel-高height-宽width,
    eg.图像的shape要是(512, 768, 3)那就传参 dataformats='HWC'
    """
```


应用如下：

```python
from torch.utils.tensorboard import SummaryWriter  
import numpy as np  
from PIL import Image  
  
# 处理图片  
image_path = "data/train/ants_image/0013035.jpg"  
img_PIL = Image.open(image_path)  
# 注意下一行是可以用np.array将PIL图片转换成numpy中的格式！
img_array = np.array(img_PIL)  
print(type(img_array))  # <class 'numpy.ndarray'>  
print(img_array.shape)  # (512, 768, 3)  
  
# writer  
writer = SummaryWriter("logs")  
writer.add_image("test", img_array, 1, dataformats='HWC')  
# 1 代表 global_step=1
writer.close()
```

结果如下：
![[Pasted image 20250220100640.png|375]]


### transforms

引用的库：
```python
from torchvision import transforms  
```

#### transforms.ToTensor 

作用：把图片转化成张量（tensor）


![[Pasted image 20250220102720.png|550]]


```python
from PIL import Image  
from torchvision import transforms  
  
img_path = "hymenoptera_data/train/ants/6240329_72c01e663e.jpg"  
img = Image.open(img_path)  

# 使用transforms.ToTensor()
# 1.创建实例. ToTensor实际上是一个类，没有__init__但是有__call__，所以创建实例的时候无需传参。
tensor_trans = transforms.ToTensor()  
# 2.调用实例.由上所述，调用这个实例的时候需要传入图片。
tensor_img = tensor_trans(img)  
  
print(tensor_img)
```


输出结果就是一个张量（三维的），如下图所示。
![[Pasted image 20250220111801.png|425]]

#### transforms.Normalize

`torchvision.transforms.Normalize` 是 PyTorch 中用于归一化图像数据的工具，常用于数据预处理阶段。它通过指定每个通道的均值（`mean`）和标准差（`std`），将图像像素值调整到一个标准分布，有助于模型训练。

##### 核心用法

```python
from torchvision import transforms

# 定义归一化参数
mean = [0.485, 0.456, 0.406]  # RGB通道的均值
std = [0.229, 0.224, 0.225]   # RGB通道的标准差

normalize = transforms.Normalize(mean=mean, std=std)
```

在实际使用中，`transforms.Normalize` 通常与其他预处理操作组合，例如 `transforms.ToTensor` 和 `transforms.Resize`。完整的预处理流程如下：

```python
preprocess = transforms.Compose([
    transforms.Resize((224, 224)),  # 调整图像大小
    transforms.ToTensor(),         # 转换为张量并归一化到 [0, 1]
    transforms.Normalize(mean=mean, std=std)  # 归一化
])
```

##### 注意事项

1. 输入数据必须是 `[0, 1]` 范围的张量，通常通过 `transforms.ToTensor()` 转换。
    
2. 输入张量的通道顺序应为 `(C, H, W)`，即通道在前。
    
3. 常用的均值和标准差（如 ImageNet 数据集）可以直接使用，也可以根据自己的数据集计算。
    

`transforms.Normalize` 是数据预处理中不可或缺的一步，能够显著提升模型的训练效果。


##### 举个例子

```python
trans_norm = transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])  
img_norm = trans_norm(img_tensor)  
writer.add_image("tensor image 2", img_norm, 2)
```
如上代码生成的图片效果：
![[Pasted image 20250220112438.png|575]]
左边为原图（img_tensor），右边为 归一化后的图像（img_norm）.


#### transforms.Resize 

`torchvision.transforms.Resize` 是 PyTorch 中用于调整图像大小的工具，常用于数据预处理阶段，以确保输入图像符合模型的输入尺寸要求。

```python
from torchvision import transforms

# 定义调整大小的操作
resize = transforms.Resize(size=(224, 224))  # 将图像调整为 224x224
```

`size` 参数可以是：

- 一个整数：图像的短边会被调整到该大小，长边会按比例缩放。
    
- 一个元组 `(H, W)`：直接指定图像的高度和宽度。

#### transforms.Compose
![[Pasted image 20250220113744.png|350]]

```python
preprocess = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor()
])
```



### downloading datasets || 下载数据集

```python
import torchvision  
  
dataset_transform = torchvision.transforms.Compose([  
    torchvision.transforms.ToTensor()  
])  

train_set = torchvision.datasets.CIFAR10(
    root="./dataset",             # 数据集保存路径
    train=True,                   # 加载训练集（设置为 False 时加载测试集）
    transform=dataset_transform,  # 应用预处理操作
    download=True                 # 自动下载数据集（如果本地不存在）
)

    
test_set = torchvision.datasets.CIFAR10(  
    root="./dataset",  
    train=False,  
    transform=dataset_transform,  
    download=True)
```


`train_set` 和 `test_set` 集成了 `__getitem__` 这个魔法方法，可以直接使用 `trainset[0]` 这种语法来访问里面的内容。

`trainset[0]` 返回一个元组，里面有 2 项，可以这样访问：
```python
img, target = test_set[0]
```

访问结果如图所示。
![[Pasted image 20250220183027.png|575]]

target 是图片的类型，target=3 说明图片类型是“第三类”。这个第三类究竟是什么？——其实它是由 train_set 定义的标签，每个数字对应了一个标签。
![[Pasted image 20250220183427.png|575]]

可见 `trainset[0]` 返回的是图片是一只哈基米。


### dataloader


dataloader：像是一个垃圾压缩机（打包机），为后面的网络提供不同的数据形式

引用的库
```python
from torch.utils.data import DataLoader
```


```python
import torchvision  
from torch.utils.tensorboard import SummaryWriter  
from torch.utils.data import DataLoader  
  
test_dataset = torchvision.datasets.CIFAR10(  
    root="./dataset",  
    train=False,  
    transform=torchvision.transforms.ToTensor(),  
    download=True)  
  
# 创建测试数据集的 DataLoader
test_loader = DataLoader(
    dataset=test_dataset,  # 测试数据集
    batch_size=64,         # 每个批次的样本数量
    shuffle=True,          # 是否随机打乱数据
    num_workers=0,         # 数据加载的线程数
    drop_last=True         # 是否丢弃最后一个不完整的批次
)

# 应用
writer = SummaryWriter("logs")  
i = 0  
for data in test_loader:  
    imgs, targets = data  
    # print(imgs)  
    # print(targets)    
    writer.add_images("dataloader", imgs, i)  
    i += 1  
  
# imgs, targets = test_loader[0] 
# 不能像上面这样写 ! 'DataLoader' object does not support indexing
  
writer.close()
```


## Nerual Network Layers Usage || 神经网络层的应用

引入的文件：
```python
import torch  
from torch import nn
```

### nn. Module

介绍文档说的已经很清楚了

![[Pasted image 20250221144844.png|475]]

具体用法在下面即可见到



### nn.Conv2d || 卷积层

下面这一坨代码不可谓不是失败之作，虽然能跑，但是还是奇丑无比。特意让 kimi 写了一下注释，解释了一下这些行都在干什么。同时记录一下自己的烂活（后面会变好的吧）

```python
import PIL  
import torch  
import torchvision  
from torch import nn  
from torch.nn import Conv2d  
from torch.utils.data import DataLoader  
from torch.utils.tensorboard import SummaryWriter  
from torchvision import transforms  
from torchvision.transforms.functional import pil_to_tensor  

class My_nn(nn.Module):  
    def __init__(self):  
        super(My_nn, self).__init__()  
        self.conv1 = Conv2d(
					        in_channels=3,
					        out_channels=6,
					        kernel_size=3,
					        stride=1,
					        padding=0)  
  
    def forward(self, x) -> torch.Tensor:  
        x = self.conv1(x)  
        return x  
  
mynn = My_nn()  
print(mynn)  
# 输出结果：  
# My_nn(  
#   (conv1): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1))  
# )  
  
  
# 图像处理，注释对应的代码在注释的下面。  
img = PIL.Image.open("hymenoptera_data/train/bees/95238259_98470c5b10.jpg")  
tensor_trans = transforms.ToTensor()  
  
# 将图像转换为 PyTorch 张量  
img = tensor_trans(img)  # 输出: <class 'torch.Tensor'>  
  
# 在第 0 维增加一个维度，  
# 将形状从 [3, H, W] 转换为 [1, 3, H, W]，  
# 以符合模型输入的 batch_size 要求  
img = torch.unsqueeze(img, 0)
  
# 打印img的类型和形状  
print(type(img))  # 输出: <class 'torch.Tensor'>  
print(img.shape)  # 输出: torch.Size([1, 3, 333, 500])  
  
writer = SummaryWriter("logs")  
  
# 对输入图像进行卷积操作  
output = mynn(img)  # 输出: torch.Size([1, 6, 331, 498])  
  
# 打印卷积后的输出张量形状  
print(output.shape)  # 输出: torch.Size([1, 6, 331, 498])  
  
# 将卷积后的张量重塑为适合可视化的形式  
_, _, h, w = output.shape  
output_modified = torch.reshape(output, (-1, 3, h, w))  
print(output_modified.shape)  # 输出: torch.Size([2, 3, 331, 498])  

writer.add_images("one pic conv", img, 1)
writer.add_images("one pic conv", output_modified, 2)
writer.close()
```


这段代码的运行结果是：

![[Pasted image 20250222105427.png|500]]

用 CIFAR 10 的数据集也能这么搞，训练结果如下

![[Pasted image 20250222111127.png|275]]

重点说一下：

```python
self.conv1 = Conv2d(
    in_channels=3,   # 输入特征图的通道数，这里为3，表示输入是RGB图像
    out_channels=6,  # 输出特征图的通道数，即卷积核的数量
    kernel_size=3,   # 卷积核的大小，这里是一个3x3的卷积核
    stride=1,        # 卷积的步长，即每次卷积移动的像素数
    padding=0        # 边缘填充的像素数，这里为0，表示不进行填充
)
```

这个贵物就是二维卷积层，它接收的输入是一个 **四维张量**，其形状通常表示为 `(batch_size, in_channels, height, width)`。
（即：其格式为 `(batch_size, in_channels, height, width)`）

RGB 图像有三个通道，所以 in_channels = 3

所以这就是为什么前面要 `img = torch.unsqueeze(img, 0)` 这个操作，就是要让单个图片变成一个图片组（batch），同时 `batch_size = 1`。


还有，关于这几个参数：padding, strides, dilation
原网址：
```
https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md
```
**↓这是No padding, no strides**
![[no_padding_no_strides.gif|119]]

**↓padding = 1, no strides**
![[same_padding_no_strides.gif|145]]

**↓No padding, strides**
![[no_padding_strides 2.gif|119]]

**↓No padding, no stride, dilation**
注意一点就是，dilation 默认的值是 1，不是 0！
![[dilation.gif|120]]



### nn.MaxPool2d || 池化层

如图
![[Pasted image 20250222112010.png|550]]


![[Pasted image 20250222112107.png|425]]

**注意 stride 的默认参数是 kernel_size（上图中为 3）**

代码略过了，跟上面差不多

### nn.ReLU & other activation functions || 激活函数

```python
import torch  
from torch import nn  
  
  
input = torch.arange(-5,20)  
  
input = torch.reshape(input, (1,1,5,5))  
print(input)  
  
class My_relu(nn.Module):  
    def __init__(self):  
        super(My_relu, self).__init__()  
        self.relu1 = nn.ReLU()  
  
    def forward(self, input):  
        output = self.relu1(input)  
        return output  
  
myfunc = My_relu()  
output = myfunc(input)  
print(output)
```

输出结果如下
![[Pasted image 20250222130556.png|275]]

### nn.Sequential

（partly powered by kimi）

==功能==

- **快捷顺序堆叠模块**：将多个神经网络模块按顺序串接，简化层与层之间的手动连接，特别适合构建连续层级的网络结构。
    
- **方便管理与调试**：整个模块被视为独立实体，便于复用、保存或迁移。
    

==示例用法==


```python
class Myseq(nn.Module):  
    def __init__(self):  
        super(Myseq, self).__init__()  
        self.conv1 = nn.Conv2d(in_channels=3,  
                               out_channels=32,  
                               kernel_size=5,  
                               padding=2)  
        self.maxpool1 = nn.MaxPool2d(kernel_size=2)  
        self.conv2 = nn.Conv2d(32, 32, 5, padding=2)  
        self.maxpool2 = nn.MaxPool2d(2)  
        self.conv3 = nn.Conv2d(32, 32, 5, padding=2)  
        self.maxpool3 = nn.MaxPool2d(2)  
        self.flatten = nn.Flatten()  
        self.linear1 = nn.Linear(1024, 64)  
        self.linear2 = nn.Linear(64, 10)  
  
  
        self.model1 = nn.Sequential(  
            self.conv1,  
            self.maxpool1,  
            self.conv2,  
            self.maxpool2,  
            self.conv3,  
            self.maxpool3,  
            self.flatten,  
            self.linear1,  
            self.linear2  
        )  
  
  
    def forward(self, x):  
        x = self.model1(x)  
        return x
```

这一长条代码实现功能的可视化如下：
![[Pasted image 20250222154357.png|550]]

- **优点**：自动将输入传递至下一层，避免繁琐的输入赋值操作，代码更简洁可读。
    

**`writer.add_graph()` 应用**

==功能==

- **可视化模型结构**：将模型的计算图结构保存到 TensorBoard 文件中，包括各层节点、输入输出关系等，便于直观查看。
    
- **调试与分析**：有助于排查模型设计错误，理解网络数据流向。
    

==示例用法==

```python
x = torch.randint(1,10,(64, 3, 32, 32)).float()  
print(x.shape)   # torch.Size([64, 3, 32, 32])  
  
seq = Myseq()  
  
# output = seq(x)  
# print(output.shape)  # torch.Size([64, 10])
# print(output[0])  # tensor([ 0.9006, -0.2945, -0.2323, -0.3727, -0.1290,  0.0100,  0.2389,  0.2414, -0.3818,  0.0179], grad_fn=<SelectBackward0>)
# 注：add_graph无需输入output.
  
writer = SummaryWriter("logs")  
writer.add_graph(seq, x)  
writer.close()
```

- `add_graph()`中输入 `seq`（模块）和 `x`（输入数据）。`x` 的形状需与模型输入一致，可通过 `.rand()` 或 `.randint()` 等生成虚拟数据。
    
- **用途**：运行后打开 TensorBoard（`tensorboard --logdir=logs`）即可查看详细模型结构。


打开 tensorboard 后，会出现一个新的选项 graphs
![[Pasted image 20250222154850.png|375]]

双击可以打开图里面的东西
![[Pasted image 20250222154920.png|550]]




### loss || 损失函数


#### 均方误差损失（MSE）

均方误差损失用于回归问题，计算公式如下：

![[Pasted image 20250222171929.png|184]]

- $n$：样本数量
    
- $y_i$ ​：真实值
    
- $\hat{y}_i$ ​：预测值
    


#### L1 损失

L1 损失用于回归问题，对离群值的敏感度较低，计算公式如下：

![[Pasted image 20250222172206.png|217]]

- $n$：样本数量
    
- $y_i$ ​：真实值
    
- $\hat{y}_i$ ​：预测值


**E.g.**
![[Pasted image 20250222172243.png|250]]



#### 交叉熵损失

交叉熵损失用于分类问题。

![[Pasted image 20250222172517.png|600]]


#### 代码

```python

# 设置数据集
cifar_set = torchvision.datasets.CIFAR10("dataset",  
			train=False,                                         						transform=torchvision.transforms.ToTensor(),  
			download=True  
			)  
cifar_loader = DataLoader(cifar_set, 64)

# 定义class Myseq(nn.Module)
# 与上文nn.Sequential中完全相同，略

seq = Myseq()  
  
loss = nn.CrossEntropyLoss()  
  
for data in cifar_loader:  
    imgs, targets = data  
    output = seq(imgs)  
    result_loss = loss(output, targets) # 计算交叉熵损失
    result_loss.backward()  			# 后向传播,注意这一步设置了梯度
    print(result_loss.item())
```

经过观察，最后一行打印出来的东西基本上都在 2.2-2.3 之间
![[Pasted image 20250222173619.png|110]]


### optimizer || 优化器

```python
# 引用的库
from torch import optim
```



数据集和 class Myseq 与上面的完全相同，略

下面是只训练一个 epoch 的结果（因为只有一个 epoch，没有加循环）
```python
seq = Myseq()  
  
loss = nn.CrossEntropyLoss()  
# 传参：最主要的 2个是 [module class].parameters 和学习率  
optimizer = optim.SGD(seq.parameters(),lr=0.01)  
  
sum_loss = 0  
for data in cifar_loader:  
    imgs, targets = data  
    output = seq(imgs)  
    result_loss = loss(output, targets)  
    optimizer.zero_grad()  # 清空梯度  
    result_loss.backward() # 设置梯度  
    optimizer.step()       # 按照梯度 优化参数  
    sum_loss += result_loss  
  
print(sum_loss)
```

下面这张图展示了加上 optimizer 和没有加的区别。
![[Pasted image 20250222180230.png|625]]


训练 20 个 epoch，代码如下

```python
for epoch in range(20):  
    sum_loss = 0  
    for data in cifar_loader:  
        imgs, targets = data  
        output = seq(imgs)  
        result_loss = loss(output, targets)  
        optimizer.zero_grad()  # 清空梯度  
        result_loss.backward() # 设置梯度  
        optimizer.step()       # 按照梯度 优化参数  
        sum_loss += result_loss  
  
    print(f"epoch{epoch}, sum loss = {sum_loss}")
```
效果如下
![[Pasted image 20250222180809.png|250]]


![[Pasted image 20250222181312.png|425]]





## Models on the internet || 网络上的模型

```python
# 引用的库
import torchvision
```

以 `vgg16` 为例研究网络上的模型。
![[Pasted image 20250222195252.png|600]]

### 下载网络上的模型
下载 `vgg16`:
```python
import torchvision
vgg16_false = torchvision.models.vgg16(pretrained=False)  
vgg16_true = torchvision.models.vgg16(pretrained=True)  
print("OK")
# 下载之后就保存在电脑里，不用再去下载。但是这几行代码还是得有的
```

`pretrained` 参数设置为 `false` 的时候，就只下载神经网络的结构，不下载其参数。
反之则下载参数与结构，如上文所说有 500 MB 之大。

`vgg16` 的后面几层如图所示，可见它是一个 1000 分类的模型。
![[Pasted image 20250222195617.png|450]]


为什么是 1000 分类的模型：imagenet 比赛要求的是 1000 分类任务
![[Pasted image 20250222195732.png|575]]


### 修改网络上的模型

```python
# 在最后面加东西
vgg16_true.add_module('add_linear', nn.Linear(1000, 10))
print(vgg16_true)
```

结果如下
![[Pasted image 20250222200316.png|475]]


```python
# 在某一组的后面加东西
vgg16_true.classifier.add_module('add_linear', nn.Linear(1000, 10))  
print(vgg16_true)
```

![[Pasted image 20250222200623.png|475]]


```python
# 更改原先模型的内容
vgg16_true.classifier[2] = nn.Dropout(p=0.7, inplace=False)  
vgg16_true.classifier[6] = nn.Linear(4096, 10,bias=True)  
print(vgg16_true)
```
![[Pasted image 20250222200902.png|425]]

以上这些更改不是永久的。

### 网络模型的保存与读取

```python
torch.save()
torch.load()
```

```python
# 文件:model_save.py

# 导入库文件
import torch  
import torchvision  
from torch import nn  
vgg16_false = torchvision.models.vgg16(pretrained=False)  
vgg16_true = torchvision.models.vgg16(pretrained=True)  

# 修改模型
vgg16_true.classifier[2] = nn.Dropout(p=0.7, inplace=False)  
vgg16_true.classifier[6] = nn.Linear(4096, 10,bias=True)  
# vgg16_false.add_module("test adding", nn.Linear(1000, 10))  
print(vgg16_true)  
# 保存方式1：保存结构+参数  
torch.save(vgg16_true, "vgg16_method1.pth")  

# 保存方式2：仅保存参数  
torch.save(vgg16_false.state_dict(),"vgg16_method2.pth")  
print("Finished")
```

```python
# 文件:model_load.py
import torch  
import torchvision  
  
# 方式1——加载模型  
vgg16_load_1 = torch.load("vgg16_method1.pth")  
print(vgg16_load_1)  
print("---------------------------")  
  
# 方式2——加载模型  
vgg16_load_2 = torchvision.models.vgg16(pretrained=False)  
source = torch.load("vgg16_method2.pth")  
print(type(source))  
vgg16_load_2.load_state_dict(source)  
print(vgg16_load_2)
```

Q: 为什么在 `model_save.py` 中要把 `vgg_16_false` 的修改那一行给注释掉呢？
A: 仅保存参数的时候修改模型（增加层数）再存储，会导致存储的参数变多（多出来的部分是修改的部分）。在读取模型的时候，仍然用 `torchvision.models.vgg16(pretrained=False)` 这个指令的话，就会导致参数过多，放不下。
报错信息如下图所示：
![[Pasted image 20250222205249.png|550]]

## Basic flow to train a model || 模型训练基本流程

感谢 bilibili@我是土堆，前面的内容也出自他的课程：
PyTorch深度学习快速入门教程（绝对通俗易懂！）【小土堆】（BV1hE411t7RN）


### 完整训练一例

`model.py`
```python
# -*- coding: utf-8 -*-
# 作者：小土堆
# 公众号：土堆碎念
import torch
from torch import nn

# 搭建神经网络
class Tudui(nn.Module):
    def __init__(self):
        super(Tudui, self).__init__()
        self.model = nn.Sequential(
            nn.Conv2d(3, 32, 5, 1, 2),
            nn.MaxPool2d(2),
            nn.Conv2d(32, 32, 5, 1, 2),
            nn.MaxPool2d(2),
            nn.Conv2d(32, 64, 5, 1, 2),
            nn.MaxPool2d(2),
            nn.Flatten(),
            nn.Linear(64*4*4, 64),
            nn.Linear(64, 10)
        )

    def forward(self, x):
        x = self.model(x)
        return x


if __name__ == '__main__':
    tudui = Tudui()
    input = torch.ones((64, 3, 32, 32))
    output = tudui(input)
    print(output.shape)
```


`train.py`
```python
# -*- coding: utf-8 -*-
# 作者：小土堆
# 公众号：土堆碎念

import torchvision
from torch.utils.tensorboard import SummaryWriter

from model import *
# 准备数据集
from torch import nn
from torch.utils.data import DataLoader

train_data = torchvision.datasets.CIFAR10(root="../data", train=True, transform=torchvision.transforms.ToTensor(),
                                          download=True)
test_data = torchvision.datasets.CIFAR10(root="../data", train=False, transform=torchvision.transforms.ToTensor(),
                                         download=True)

# length 长度
train_data_size = len(train_data)
test_data_size = len(test_data)
# 如果train_data_size=10, 训练数据集的长度为：10
print("训练数据集的长度为：{}".format(train_data_size))
print("测试数据集的长度为：{}".format(test_data_size))


# 利用 DataLoader 来加载数据集
train_dataloader = DataLoader(train_data, batch_size=64)
test_dataloader = DataLoader(test_data, batch_size=64)

# 创建网络模型
tudui = Tudui()

# 损失函数
loss_fn = nn.CrossEntropyLoss()

# 优化器
# learning_rate = 0.01
# 1e-2=1 x (10)^(-2) = 1 /100 = 0.01
learning_rate = 1e-2
optimizer = torch.optim.SGD(tudui.parameters(), lr=learning_rate)

# 设置训练网络的一些参数
# 记录训练的次数
total_train_step = 0
# 记录测试的次数
total_test_step = 0
# 训练的轮数
epoch = 10

# 添加tensorboard
writer = SummaryWriter("../logs_train")

for i in range(epoch):
    print("-------第 {} 轮训练开始-------".format(i+1))

    # 训练步骤开始
    tudui.train()
    for data in train_dataloader:
        imgs, targets = data
        outputs = tudui(imgs)
        loss = loss_fn(outputs, targets)

        # 优化器优化模型
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_train_step = total_train_step + 1
        if total_train_step % 100 == 0:
            print("训练次数：{}, Loss: {}".format(total_train_step, loss.item()))
            writer.add_scalar("train_loss", loss.item(), total_train_step)

    # 测试步骤开始
    tudui.eval()
    total_test_loss = 0
    total_accuracy = 0
    with torch.no_grad():
        for data in test_dataloader:
            imgs, targets = data
            outputs = tudui(imgs)
            loss = loss_fn(outputs, targets)
            total_test_loss = total_test_loss + loss.item()
            accuracy = (outputs.argmax(1) == targets).sum()
            total_accuracy = total_accuracy + accuracy

    print("整体测试集上的Loss: {}".format(total_test_loss))
    print("整体测试集上的正确率: {}".format(total_accuracy/test_data_size))
    writer.add_scalar("test_loss", total_test_loss, total_test_step)
    writer.add_scalar("test_accuracy", total_accuracy/test_data_size, total_test_step)
    total_test_step = total_test_step + 1

    torch.save(tudui, "tudui_{}.pth".format(i))
    print("模型已保存")

writer.close()
```


### 利用 GPU 加速

==方法 1：==
![[Pasted image 20250223101522.png|160]]
以上 3 项，`xxx = xxx.cuda()`
结束

上面那一大坨代码，改动的地方有：
（网络）模型
```python
tudui = Tudui()
if torch.cuda.is_available():
	tudui = tudui.cuda()         # cuda acceleration
```

损失函数
```python
loss_fn = nn.CrossEntropyLoss()
if torch.cuda.is_available():
	loss_fn = loss_fn.cuda()     # cuda acceleration
```

*模型和损失函数可以不复制（可选），数据必须复制*

数据
```python
# 训练步骤和测试步骤都可以使用cuda加速
for data in train_dataloader:
    imgs, targets = data
    if torch.cuda.is_available():
	    imgs = imgs.cuda()        # cuda acceleration
	    targets = targets.cuda()  # cuda acceleration


```

==方法 2：==

使用 `torch.device()` 和 `xx = xx.to()`


代码前面先定义一下使用什么玩意来训练
```python
# 可行的3种情况
device = torch.device("cpu")
device = torch.device("cuda")
device = torch.device("cuda:0")
```

后面对于模型、损失函数、数据：
```python
tudui = Tudui()
tudui = tudui.to(device)
```

### 训练计时

```python
import time

# berofe train starts
start_time = time.time()

# training
end_time = time.time()

# print time
print(end_time - start_time)
```

